#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
from pathlib import Path
import re
import pandas as pd


def _normalize_key(s: str) -> str:
    """Name ë§¤ì¹­ì„ ìœ„í•œ ì •ê·œí™”: ì†Œë¬¸ì, ì•ë’¤ê³µë°± ì œê±°, ì—°ì†ê³µë°± ë‹¨ì¼í™”."""
    if not isinstance(s, str):
        return ""
    s = " ".join(s.strip().split())
    return s.lower()

def load_meta(path: Path) -> pd.DataFrame:
    """
    models_meta.(csv|parquet) ë¥¼ ì½ì–´ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë°˜í™˜.
    í•„ìˆ˜ ì»¬ëŸ¼: Name, Input Resolution, Operations, Parameters
    """
    if not path.exists():
        raise FileNotFoundError(f"Enrichment file not found: {path}")

    if path.suffix.lower() == ".csv":
        meta = pd.read_csv(path)
    elif path.suffix.lower() in (".parquet", ".pq"):
        meta = pd.read_parquet(path)
    else:
        raise ValueError("Unsupported enrichment format. Use CSV or Parquet.")

    # ì—´ ì´ë¦„ ë°©ì–´ì  í‘œì¤€í™”
    meta.columns = [str(c).strip() for c in meta.columns]
    rename_map = {
        "InputResolution": "Input Resolution",
        "Input_Resolution": "Input Resolution",
        "Ops": "Operations",
        "Params": "Parameters",
    }
    for k, v in rename_map.items():
        if k in meta.columns and v not in meta.columns:
            meta.rename(columns={k: v}, inplace=True)

    required = ["Name", "Input Resolution", "Operations", "Parameters"]
    missing = [c for c in required if c not in meta.columns]
    if missing:
        raise ValueError(f"Missing columns in enrichment: {missing}")

    # í‚¤ ì •ê·œí™” ì»¬ëŸ¼ ì¶”ê°€
    meta["_match_key_"] = meta["Name"].astype(str).map(_normalize_key)

    # ì¤‘ë³µ Name ì •ì±…: ë§ˆì§€ë§‰(ê°€ì¥ ì•„ë˜) ë ˆì½”ë“œê°€ ìš°ì„ 
    meta = meta.drop_duplicates(subset=["_match_key_"], keep="last")

    # íƒ€ì… ì •ë¦¬
    meta["Operations"] = pd.to_numeric(meta["Operations"], errors="coerce")
    meta["Parameters"] = pd.to_numeric(meta["Parameters"], errors="coerce")

    return meta[["_match_key_", "Input Resolution", "Operations", "Parameters"]]


# ----------------------------
# Helpers & Constants
# ----------------------------
COLUMN_ALIAS_MAP = {
    # í‘œì¤€í™” ëŒ€ìƒ(ì˜¤íƒˆì/ëŒ€ì²´ ëª…)
    "Raw Accu": "Raw Accuracy",
    "Raw Accuracy(20250604)": "Raw Accuracy",
    "NPU Accracy": "NPU Accuracy",
    "3npus_fps": "FPS",
    "3npus_FPS/W": "FPS/Watt",
    "reference": "Source",
    "Reference": "Source",
    "dxnn": "Compiled",
    "DXNN": "Compiled",
    "onnx": "onnx",   # íƒ€ê¹ƒì€ ì†Œë¬¸ì ë¼ë²¨
    "json": "json",   # íƒ€ê¹ƒì€ ì†Œë¬¸ì ë¼ë²¨
    "Model ID": "Name",
    # ê·¸ëŒ€ë¡œ ì“°ëŠ” ê²ƒë“¤(ìˆì„ ë•Œë§Œ rename; ì—†ìœ¼ë©´ ê±´ë„ˆëœ€)
    "Dataset": "Dataset",
    "Input Resolution": "Input Resolution",
    "Operations": "Operations",
    "Parameters": "Parameters",
    "license": "License",
    "Raw Accuracy": "Raw Accuracy",
    "NPU Accuracy": "NPU Accuracy",
    "FPS": "FPS",
    "Task": "Task",
}

FINAL_COLUMNS = [
    "Task", "Name", "Dataset", "Input Resolution", "Operations", "Parameters",
    "License", "Metric", "Raw Accuracy", "NPU Accuracy", "FPS", "FPS/Watt",
    "Source", "Compiled", "onnx", "json"
]

LINK_COLUMNS = ["Source", "Compiled", "onnx", "json"]
LINK_TEXT_MAP = {"Source": "Source", "Compiled": "Compiled", "onnx": "onnx", "json": "json"}


def create_html_link(url: str, text: str) -> str:
    """
    URLê³¼ ë§í¬ í…ìŠ¤íŠ¸(ì¢…ë¥˜)ë¥¼ ë°›ì•„ ì ì ˆí•œ ì•„ì´ì½˜ì´ í¬í•¨ëœ HTML ì•µì»¤ íƒœê·¸ë¥¼ ìƒì„±í•œë‹¤.
    - textê°€ 'Source'ì´ë©´ ë°”ë¡œê°€ê¸° ì•„ì´ì½˜, ê·¸ ì™¸ì—ëŠ” ë‹¤ìš´ë¡œë“œ ì•„ì´ì½˜ì„ ì‚¬ìš©í•œë‹¤.
    """
    if not isinstance(url, str) or not url.strip():
        return ""

    # 1. "ë°”ë¡œê°€ê¸°" ì•„ì´ì½˜ (External Link) SVG ì½”ë“œ â†—ï¸
    external_link_svg = """
    <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
       <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
       <polyline points="15 3 21 3 21 9"></polyline>
       <line x1="10" y1="14" x2="21" y2="3"></line>
    </svg>
    """

    # 2. "ë‹¤ìš´ë¡œë“œ" ì•„ì´ì½˜ SVG ì½”ë“œ ğŸ“¥
    download_svg = """
    <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
        <polyline points="7 10 12 15 17 10"></polyline>
        <line x1="12" y1="15" x2="12" y2="3"></line>
    </svg>
    """

    # 3. text ê°’ì— ë”°ë¼ ì‚¬ìš©í•  ì•„ì´ì½˜ì„ ì„ íƒ
    icon_svg = ""
    if text == "Source":
        icon_svg = external_link_svg
    else:
        icon_svg = download_svg
    
    # 4. ìµœì¢… HTML íƒœê·¸ë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜
    return f'<a href="{url}" target="_blank" rel="noopener noreferrer" title="{text}">{icon_svg.strip()}</a>'


def get_metric_type(value) -> str:
    """
    Metric ëŒ€ë¶„ë¥˜ (í…Œì´ë¸”ì˜ 'Metric' ì»¬ëŸ¼ìš©)
    """
    if not isinstance(value, str):
        return ""
    s = value.strip()
    if s.startswith("Top1"):
        return "Top1"
    if s.startswith("mAP"):
        return "mAP50" if "50" in s or "0.5" in s else "mAP"
    if s.startswith("mIoU"):
        return "mIoU"
    if s.startswith("Avg PSNR") or s.startswith("PSNR") or "SSIM" in s:
        return "PSNR/SSIM"
    if s.startswith("Val AP") or s.startswith("AP(") or s.startswith("AP ") or s.startswith("AP"):
        return "AP(Easy/Med/Hard)"
    return ""


def get_metric_detail(value) -> str:
    """
    Metric ì„¸ë¶€ ë¼ë²¨: AP(Easy)/AP(Medium)/AP(Hard) ë“± êµ¬ë¶„
    """
    if not isinstance(value, str):
        return ""
    s = value.strip()
    if "AP(Easy)" in s:
        return "AP(Easy)"
    if "AP(Medium)" in s:
        return "AP(Medium)"
    if "AP(Hard)" in s:
        return "AP(Hard)"
    if s.startswith("Top1"):
        return "Top1"
    if s.startswith("mAP@0.5") or "mAP50" in s:
        return "mAP@0.5"
    if s.startswith("mAP"):
        return "mAP"
    if s.startswith("Avg PSNR") or s.startswith("PSNR") or "SSIM" in s:
        return "PSNR/SSIM"
    if s.startswith("Val AP") or s.startswith("AP(") or s.startswith("AP ") or s.startswith("AP"):
        return "AP"
    return ""


# ---- Accuracy ìˆ«ì ì¶”ì¶œ(ìš”ì²­ ê·œì¹™) -------------------------------
_TOP1_RE   = re.compile(r'\bTop-?1\b[^0-9\-+]*([-+]?\d+(?:\.\d+)?)', re.IGNORECASE)
_MAP_MAIN  = re.compile(r'\bmAP\b(?!\s*@?\s*0?\.?5|50)\s*[:=]?\s*([-+]?\d+(?:\.\d+)?)', re.IGNORECASE)
_MAP_050   = re.compile(r'\bmAP(?:@?\s*0?\.?5|50)\b\s*[:=]?\s*([-+]?\d+(?:\.\d+)?)', re.IGNORECASE)
_FIRST_NUM = re.compile(r'([-+]?\d+(?:\.\d+)?)')

_AP_PREAMBLE_RE = re.compile(r'\b(?:Val\s*)?AP\b', re.IGNORECASE)
_AP_PAIR_RE     = re.compile(r'\b(Easy|Medium|Hard)\b\s*[:=]?\s*([-+]?\d+(?:\.\d+)?)', re.IGNORECASE)
_AP_FUNC_RE     = re.compile(r'AP\((Easy|Medium|Hard)\)\s*[:=]?\s*([-+]?\d+(?:\.\d+)?)', re.IGNORECASE)
_NUM_RE         = re.compile(r'[-+]?\d+(?:\.\d+)?')

_PSNR_RE = re.compile(r'\b(?:Avg\s*)?PSNR\b[^0-9\-+]*([-+]?\d+(?:\.\d+)?)', re.IGNORECASE)
_SSIM_RE = re.compile(r'\b(?:Avg\s*)?SSIM\b[^0-9\-+]*([-+]?\d+(?:\.\d+)?)', re.IGNORECASE)


def extract_ap_triple_joined(raw: str) -> str:
    """
    'Val AP (Easy 95.44 / Medium 93.95 / Hard 85.664)' ê°™ì€ ë¬¸ìì—´ì—ì„œ
    Easy/Medium/Hard ê°’ì„ ë½‘ì•„ '95.44 / 93.95 / 85.664'ë¡œ ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜.
    """
    if not isinstance(raw, str):
        return ""
    s = raw.strip()
    if not _AP_PREAMBLE_RE.search(s):
        return ""

    # 1) ë¼ë²¨-ê°’ ìŒ ìš°ì„ 
    pairs = {}
    for lbl, val in _AP_PAIR_RE.findall(s):
        pairs[lbl.capitalize()] = val
    for lbl, val in _AP_FUNC_RE.findall(s):
        pairs[lbl.capitalize()] = val

    ordered = [pairs.get("Easy"), pairs.get("Medium"), pairs.get("Hard")]
    if any(v is not None for v in ordered):
        return " / ".join(v or "" for v in ordered)

    # 2) ë¼ë²¨ì´ ì—†ìœ¼ë©´ ê´„í˜¸ ì•ˆ ë“±ì—ì„œ ìˆ«ìë§Œ 3ê°œ ìˆœì„œëŒ€ë¡œ ì§‘ê³„
    nums = _NUM_RE.findall(s)
    if len(nums) >= 3:
        return " / ".join(nums[:3])

    return ""


def extract_psnr_ssim_joined(raw: str) -> str:
    """
    'Avg PSNR: 31.709 / Avg SSIM: 0.8905' ê°™ì€ ë¬¸ìì—´ì—ì„œ
    '31.709 / 0.8905' í˜•íƒœë¡œ ë°˜í™˜. (ìˆœì„œ PSNR / SSIM)
    ë‹¤ì–‘í•œ í‘œê¸°(ì‰¼í‘œ, ë“±í˜¸, ê³µë°±)ë„ í—ˆìš©.
    """
    if not isinstance(raw, str):
        return ""
    s = raw.strip()

    # ë¼ë²¨ ê¸°ë°˜ ìš°ì„ 
    psnr = None
    ssim = None
    m1 = _PSNR_RE.search(s)
    m2 = _SSIM_RE.search(s)
    if m1:
        psnr = m1.group(1)
    if m2:
        ssim = m2.group(1)
    if psnr or ssim:
        return " / ".join([psnr or "", ssim or ""]).strip()

    # ë¼ë²¨ì´ ì—†ê³  ìˆ«ìë§Œ ë‚˜ì—´ëœ ê²½ìš°: ì•ì˜ ë‘ ìˆ«ìë¥¼ PSNR/SSIMìœ¼ë¡œ ê°„ì£¼
    nums = _NUM_RE.findall(s)
    if len(nums) >= 2:
        return f"{nums[0]} / {nums[1]}"
    return ""


def extract_primary_accuracy(value) -> str:
    """
    Raw Accuracy ë¬¸ìì—´ì—ì„œ í‘œì‹œìš© ìˆ«ì í•˜ë‚˜ë§Œ ë½‘ì•„ë‚¸ë‹¤.
    ìš°ì„ ìˆœìœ„: Top1 > mAP(ê¸°ë³¸) > mAP@0.5/50 > ì²« ìˆ«ì(Fallback)
    """
    if not isinstance(value, str):
        return ""
    s = value.strip()
    for pat in (_TOP1_RE, _MAP_MAIN, _MAP_050, _FIRST_NUM):
        m = pat.search(s)
        if m:
            return m.group(1)
    return ""
# ------------------------------------------------------------------

def _lower_alias_map(alias_map: dict) -> dict:
    """ì¼€ì´ìŠ¤ ë¬´ê´€ ë§¤í•‘ì„ ìœ„í•´ ì†Œë¬¸ì í‚¤ë¡œ ë³€í™˜í•œ alias ë§µì„ ë§Œë“ ë‹¤."""
    return {str(k).strip().lower(): v for k, v in alias_map.items()}


def dedupe_and_bfill_column(df: pd.DataFrame, colname: str) -> pd.DataFrame:
    """
    ë™ì¼ ë¼ë²¨ì´ ì—¬ëŸ¬ ë²ˆ ìƒê²¼ì„ ë•Œ ì¢Œâ†’ìš° ìš°ì„ ìœ¼ë¡œ bfillí•˜ì—¬ í•˜ë‚˜ë¡œ ë³‘í•©.
    """
    cols = df.filter(regex=fr"^{re.escape(colname)}$", axis=1)
    if cols.shape[1] > 1:
        merged = cols.bfill(axis=1).iloc[:, 0]
        extra = list(cols.columns[1:])
        df.drop(columns=extra, inplace=True)
        df[colname] = merged
    return df


def _metric_accuracy_parsor(df: pd.DataFrame) -> pd.DataFrame:
    """
    Metric, Accuracy ê°’ì„ ì›í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜
    """
    out_rows = []
    for _, row in df.iterrows():
        raw_str = str(row.get("Raw Accuracy", ""))
        npu_str = str(row.get("NPU Accuracy", ""))

        # ê·¸ëŒ€ë¡œ ìœ ì§€ (ë‹¨, ìˆ«ìë§Œ ë‚¨ê¸°ê³  Metric/ì„¸ë¶€ ë¼ë²¨ ì •ë¦¬)
        detail = get_metric_detail(raw_str)
        major = get_metric_type(raw_str)
        new_metric = detail if detail in ("AP(Easy)", "AP(Medium)", "AP(Hard)") else major
        row = row.copy()
        row["Metric"] = new_metric
        if new_metric == "AP(Easy/Med/Hard)":
            triple = extract_ap_triple_joined(raw_str)
            row["Raw Accuracy"] = triple if triple else extract_primary_accuracy(raw_str)
            triple = extract_ap_triple_joined(npu_str)
            row["NPU Accuracy"] = triple if triple else extract_primary_accuracy(npu_str)

        elif new_metric == "PSNR/SSIM":
            pair = extract_psnr_ssim_joined(raw_str)
            row["Raw Accuracy"] = pair if pair else extract_primary_accuracy(raw_str)
            row["NPU Accuracy"] = pair if pair else extract_primary_accuracy(npu_str)

        else:
            row["Raw Accuracy"] = extract_primary_accuracy(raw_str)
            row["NPU Accuracy"] = extract_primary_accuracy(npu_str)
        out_rows.append(row)

    return pd.DataFrame(out_rows)


def normalize_and_process(df: pd.DataFrame, meta_path: Path | None = None) -> pd.DataFrame:
    """
    DataFrame ì»¬ëŸ¼ í‘œì¤€í™” + íŒŒìƒ ì»¬ëŸ¼ ìƒì„± + ë§í¬/ìˆ«ì í¬ë§·íŒ… ì ìš©
    """
    df = df.copy()

    # 0) í—¤ë” ê³µë°± ì œê±°
    df.columns = [str(c).strip() for c in df.columns]

    # 1) Task ì •ë¦¬
    if "Task" in df.columns:
        df["Task"] = df["Task"].astype(str).str.replace(r"^\d+\.\s*", "", regex=True).str.strip()
    else:
        df["Task"] = "Uncategorized Models"

    # 2) ì»¬ëŸ¼ ì´ë¦„ í‘œì¤€í™”(ì¼€ì´ìŠ¤ ë¬´ê´€ rename)
    lower_alias = _lower_alias_map(COLUMN_ALIAS_MAP)
    rename_map = {c: lower_alias[c.lower()] for c in df.columns if c.lower() in lower_alias}
    df.rename(columns=rename_map, inplace=True)

    # 2-1) Name/License ì¤‘ë³µ ë¼ë²¨ ë³‘í•©
    df = dedupe_and_bfill_column(df, "Name")
    df = dedupe_and_bfill_column(df, "License")

    # 3) Name ë³´ê°•(ì—†ê±°ë‚˜ ì „ë¶€ NaNì¼ ë•Œ)
    need_fill_name = False
    if "Name" not in df.columns:
        need_fill_name = True
    else:
        if df["Name"].isna().all():
            need_fill_name = True

    if need_fill_name:
        if "filename" in df.columns:
            df["Name"] = df["filename"]
        elif "Model ID" in df.columns:
            df["Name"] = df["Model ID"]
        else:
            df["Name"] = "N/A"

    # 4) Metric, Accuracy
    #if "Raw Accuracy" not in df.columns:
    #    df["Raw Accuracy"] = ""
    #if "NPU Accuracy" not in df.columns:
    #    df["NPU Accuracy"] = ""
    df = _metric_accuracy_parsor(df)

    # 5) í•„ìˆ˜ ì»¬ëŸ¼ ë³´ê°•
    for col in FINAL_COLUMNS:
        if col not in df.columns:
            df[col] = ""

    # 6) ë§í¬ ì»¬ëŸ¼ ì•µì»¤ ì²˜ë¦¬
    for col in LINK_COLUMNS:
        df.loc[:, col] = df[col].apply(lambda url: create_html_link(url, LINK_TEXT_MAP[col]))

    # 7) ìˆ«ì í¬ë§·íŒ…
    for col in ["Operations", "Parameters", "FPS", "FPS/Watt"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df["Operations"] = df["Operations"].map(lambda x: f"{x:,.2f}" if pd.notna(x) else "")
    df["Parameters"] = df["Parameters"].map(lambda x: f"{x:,.2f}" if pd.notna(x) else "")
    df["FPS"] = df["FPS"].map(lambda x: f"{x:,.0f}" if pd.notna(x) else "")
    df["FPS/Watt"] = df["FPS/Watt"].map(lambda x: f"{x:,.2f}" if pd.notna(x) else "")

    if "Name" not in df.columns:
        df["Name"] = "N/A"
    df["_match_key_"] = df["Name"].astype(str).map(_normalize_key)

    if "License" in df.columns:
        df["License"] = df["License"].fillna("Not Specified")
        df.loc[df["License"].astype(str).str.strip() == "", "License"] = "Not Specified"


    # --- ì™¸ë¶€ ë³´ê°• íŒŒì¼ì´ ìˆìœ¼ë©´ Left Join ---
    if meta_path is not None:
        meta = load_meta(meta_path)
        df = df.merge(meta, on="_match_key_", how="left", suffixes=("", "_meta"))

        # CSVì— ì—†ë˜ ê°’ë§Œ ë©”íƒ€ë¡œ ì±„ìš°ê¸°(ê¸°ì¡´ê°’ì´ ë¹„ì—ˆì„ ë•Œë§Œ ë®ì–´ì“°ê¸°)
        def _fill_if_empty(base_col: str, meta_col: str):
            if base_col not in df.columns:
                df[base_col] = ""
            df[base_col] = df[base_col].where(df[base_col].astype(str).str.len() > 0, df[meta_col])

        _fill_if_empty("Input Resolution", "Input Resolution_meta")
        _fill_if_empty("Operations",        "Operations_meta")
        _fill_if_empty("Parameters",        "Parameters_meta")

        # ë©”íƒ€ ì»¬ëŸ¼ì€ ì •ë¦¬
        df.drop(columns=[c for c in df.columns if c.endswith("_meta")], inplace=True)

    # 8) ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ
    df = df[FINAL_COLUMNS]
    return df


def dataframe_grouped_html(df: pd.DataFrame) -> str:
    """
    Task ìˆœì„œëŒ€ë¡œ ì„¹ì…˜(<h2>) + í…Œì´ë¸”(ê°ê°ì— Task ì»¬ëŸ¼ í¬í•¨) HTML ìƒì„±
    """
    parts = []
    task_order = df["Task"].astype(str).tolist() if "Task" in df.columns else []
    task_order = pd.Series(task_order).drop_duplicates().tolist() if task_order else ["Uncategorized Models"]

    for task in task_order:
        sub = df[df["Task"] == task]
        if sub.empty:
            continue
        parts.append(f'<h2 class="task-title">{task}</h2>')
        table_html = sub.to_html(
            escape=False,
            index=False,
            classes="model-zoo-table",
            na_rep=""
        )
        parts.append(f'<div class="table-container">{table_html}</div>')

    return "\n".join(parts)


def build_full_html(body: str) -> str:
    """
    ì „ì²´ HTML ë¬¸ì„œ ìŠ¤ì¼ˆë ˆí†¤ + ìŠ¤íƒ€ì¼
    """
    return f"""<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>DX Model Zoo</title>
  <style>
    :root {{
      --bg: #f8f9fa;
      --fg: #212529;
      --muted: #495057;
      --border: #dee2e6;
      --accent: #0d6efd;
      --card: #ffffff;
      --thead: #e9ecef;
    }}
    * {{ box-sizing: border-box; }}
    body {{
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      margin: 0;
      padding: 24px;
      background: var(--bg);
      color: var(--fg);
      line-height: 1.5;
    }}
    h1 {{
      margin: 0 0 28px 0;
      font-size: 2rem;
      color: #343a40;
    }}
    h2.task-title {{
      margin: 32px 0 12px 0;
      font-size: 1.5rem;
      color: #343a40;
      padding-bottom: 6px;
      border-bottom: 2px solid var(--border);
    }}
    .table-container {{
      overflow-x: auto;
      border-radius: 10px;
      box-shadow: 0 4px 8px rgba(0,0,0,.3);
      background: var(--card);
      margin-bottom: 22px;
    }}
    table.model-zoo-table {{
      border-collapse: collapse;
      width: 100%;
      font-size: 0.92rem;
      table-layout: auto;
    }}
    table.model-zoo-table th, table.model-zoo-table td {{
      border: 1px solid var(--border);
      padding: 10px 12px;
      text-align: center;
      vertical-align: middle;
      white-space: nowrap;
    }}
    table.model-zoo-table thead th {{
      background: #c0c0c0;
      color: var(--muted);
      font-weight: 600;
      position: sticky;
      top: 0;
      z-index: 1;
    }}
    table.model-zoo-table tbody tr:nth-of-type(even) {{
      background-color: #e6e6e0;
    }}
    table.model-zoo-table tbody tr:hover {{
      background-color: #f3f5f7;
    }}
    table.model-zoo-table a {{
      text-decoration: none;
      color: var(--accent);
      font-weight: 500;
    }}
    table.model-zoo-table a:hover {{ text-decoration: underline; }}
    @media (max-width: 768px) {{
      table.model-zoo-table th, table.model-zoo-table td {{
        padding: 8px 10px;
        font-size: 0.88rem;
      }}
    }}
  </style>
</head>
<body>
  <h1>DX Model Zoo</h1>
  {body}
</body>
</html>
"""


def generate_model_zoo_html(csv_path: Path, html_path: Path, meta_path: Path | None = None) -> None:
    if not csv_path.exists():
        raise FileNotFoundError(f"Input CSV not found: {csv_path}")

    print(f"meta = {meta_path}")
    df_raw = pd.read_csv(csv_path)
    df_processed = normalize_and_process(df_raw, meta_path=meta_path)
    body_html = dataframe_grouped_html(df_processed)
    html = build_full_html(body_html)
    html_path.write_text(html, encoding="utf-8")
    print(f"[OK] Generated: {html_path}")


def main():
    p = argparse.ArgumentParser(description="Generate DX Model Zoo-style HTML from CSV.")
    p.add_argument("--csv", type=Path, default=Path("sample.csv"), help="Input CSV file path")
    p.add_argument("--out", type=Path, default=Path("output.html"), help="Output HTML file path")
    p.add_argument("--meta", type=Path, default=Path("meta.csv"), help="Metadata CSV file path")
    args = p.parse_args()
    generate_model_zoo_html(args.csv, args.out, args.meta)


if __name__ == "__main__":
    main()

